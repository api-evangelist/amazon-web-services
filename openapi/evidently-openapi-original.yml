openapi: 3.1.0
info:
  title: evidently
  description: >-
    <p>You can use Amazon CloudWatch Evidently to safely validate new features
    by serving them to a specified percentage of your users while you roll out
    the feature. You can monitor the performance of the new feature to help you
    decide when to ramp up traffic to your users. This helps you reduce risk and
    identify unintended consequences before you fully launch the feature.</p>
    <p>You can also conduct A/B experiments to make feature design decisions
    based on evidence and data. An experiment can test as many as five
    variations at once. Evidently collects experiment data and analyzes it using
    statistical methods. It also provides clear recommendations about which
    variations perform better. You can test both user-facing features and
    backend features.</p>
paths:
  /projects/{project}/evaluations:
    POST:
      summary: Batchevaluatefeature
      description: >-
        This operation assigns feature variation to user sessions. For each user
        session, you pass in an entityID that represents the user. Evidently
        then checks the evaluation rules and assigns the variation. The first
        rules that are evaluated are the override rules. If the user's entityID
        matches an override rule, the user is served the variation specified by
        that rule. Next, if there is a launch of the feature, the user might be
        assigned to a variation in the launch. The chance of this depends on the
        percentage of users that are allocated to that launch. If the user is
        enrolled in the launch, the variation they are served depends on the
        allocation of the various feature variations used for the launch. If the
        user is not assigned to a launch, and there is an ongoing experiment for
        this feature, the user might be assigned to a variation in the
        experiment. The chance of this depends on the percentage of users that
        are allocated to that experiment. If the user is enrolled in the
        experiment, the variation they are served depends on the allocation of
        the various feature variations used for the experiment.  If the user is
        not assigned to a launch or experiment, they are served the default
        variation.
      operationId: amazonWebServicesBatchEvaluateFeature
  /projects/{project}/experiments:
    GET:
      summary: Listexperiments
      description: >-
        Returns configuration details about all the experiments in the specified
        project.
      operationId: amazonWebServicesListExperiments
  /projects/{project}/features:
    GET:
      summary: Listfeatures
      description: >-
        Returns configuration details about all the features in the specified
        project.
      operationId: amazonWebServicesListFeatures
  /projects/{project}/launches:
    GET:
      summary: Listlaunches
      description: >-
        Returns configuration details about all the launches in the specified
        project.
      operationId: amazonWebServicesListLaunches
  /projects:
    GET:
      summary: Listprojects
      description: >-
        Returns configuration details about all the projects in the current
        Region in your account.
      operationId: amazonWebServicesListProjects
  /segments:
    GET:
      summary: Listsegments
      description: >-
        Returns a list of audience segments that you have created in your
        account in this Region.
      operationId: amazonWebServicesListSegments
  /projects/{project}/experiments/{experiment}:
    PATCH:
      summary: Updateexperiment
      description: >-
        Updates an Evidently experiment.  Don't use this operation to update an
        experiment's tag. Instead, use TagResource. 
      operationId: amazonWebServicesUpdateExperiment
  /projects/{project}/features/{feature}:
    PATCH:
      summary: Updatefeature
      description: >-
        Updates an existing feature. You can't use this operation to update the
        tags of an existing feature. Instead, use TagResource. 
      operationId: amazonWebServicesUpdateFeature
  /projects/{project}/launches/{launch}:
    PATCH:
      summary: Updatelaunch
      description: >-
        Updates a launch of a given feature.  Don't use this operation to update
        the tags of an existing launch. Instead, use TagResource. 
      operationId: amazonWebServicesUpdateLaunch
  /projects/{project}:
    PATCH:
      summary: Updateproject
      description: >-
        Updates the description of an existing project. To create a new project,
        use CreateProject. Don't use this operation to update the data storage
        options of a project. Instead, use UpdateProjectDataDelivery.  Don't use
        this operation to update the tags of a project. Instead, use
        TagResource. 
      operationId: amazonWebServicesUpdateProject
  /segments/{segment}:
    GET:
      summary: Getsegment
      description: >-
        Returns information about the specified segment. Specify the segment you
        want to view by specifying its ARN.
      operationId: amazonWebServicesGetSegment
  /projects/{project}/evaluations/{feature}:
    POST:
      summary: Evaluatefeature
      description: >-
        This operation assigns a feature variation to one given user session.
        You pass in an entityID that represents the user. Evidently then checks
        the evaluation rules and assigns the variation. The first rules that are
        evaluated are the override rules. If the user's entityID matches an
        override rule, the user is served the variation specified by that rule.
        If there is a current launch with this feature that uses segment
        overrides, and if the user session's evaluationContext matches a segment
        rule defined in a segment override, the configuration in the segment
        overrides is used. For more information about segments, see
        CreateSegment and Use segments to focus your audience. If there is a
        launch with no segment overrides, the user might be assigned to a
        variation in the launch. The chance of this depends on the percentage of
        users that are allocated to that launch. If the user is enrolled in the
        launch, the variation they are served depends on the allocation of the
        various feature variations used for the launch. If the user is not
        assigned to a launch, and there is an ongoing experiment for this
        feature, the user might be assigned to a variation in the experiment.
        The chance of this depends on the percentage of users that are allocated
        to that experiment. If the experiment uses a segment, then only user
        sessions with evaluationContext values that match the segment rule are
        used in the experiment. If the user is enrolled in the experiment, the
        variation they are served depends on the allocation of the various
        feature variations used for the experiment.  If the user is not assigned
        to a launch or experiment, they are served the default variation.
      operationId: amazonWebServicesEvaluateFeature
  /projects/{project}/experiments/{experiment}/results:
    POST:
      summary: Getexperimentresults
      description: >-
        Retrieves the results of a running or completed experiment. No results
        are available until there have been 100 events for each variation and at
        least 10 minutes have passed since the start of the experiment. To
        increase the statistical power, Evidently performs an additional offline
        p-value analysis at the end of the experiment. Offline p-value analysis
        can detect statistical significance in some cases where the anytime
        p-values used during the experiment do not find statistical
        significance. Experiment results are available up to 63 days after the
        start of the experiment. They are not available after that because of
        CloudWatch data retention policies.
      operationId: amazonWebServicesGetExperimentResults
  /segments/{segment}/references:
    GET:
      summary: Listsegmentreferences
      description: >-
        Use this operation to find which experiments or launches are using a
        specified segment.
      operationId: amazonWebServicesListSegmentReferences
  /tags/{resourceArn}:
    DELETE:
      summary: Untagresource
      description: Removes one or more tags from the specified resource.
      operationId: amazonWebServicesUntagResource
  /events/projects/{project}:
    POST:
      summary: Putprojectevents
      description: >-
        Sends performance events to Evidently. These events can be used to
        evaluate a launch or an experiment.
      operationId: amazonWebServicesPutProjectEvents
  /projects/{project}/experiments/{experiment}/start:
    POST:
      summary: Startexperiment
      description: >-
        Starts an existing experiment. To create an experiment, use
        CreateExperiment.
      operationId: amazonWebServicesStartExperiment
  /projects/{project}/launches/{launch}/start:
    POST:
      summary: Startlaunch
      description: Starts an existing launch. To create a launch, use CreateLaunch.
      operationId: amazonWebServicesStartLaunch
  /projects/{project}/experiments/{experiment}/cancel:
    POST:
      summary: Stopexperiment
      description: >-
        Stops an experiment that is currently running. If you stop an
        experiment, you can't resume it or restart it.
      operationId: amazonWebServicesStopExperiment
  /projects/{project}/launches/{launch}/cancel:
    POST:
      summary: Stoplaunch
      description: >-
        Stops a launch that is currently running. After you stop a launch, you
        will not be able to resume it or restart it. Also, it will not be
        evaluated as a rule for traffic allocation, and the traffic that was
        allocated to the launch will instead be available to the feature's
        experiment, if there is one. Otherwise, all traffic will be served the
        default variation after the launch is stopped.
      operationId: amazonWebServicesStopLaunch
  /test-segment-pattern:
    POST:
      summary: Testsegmentpattern
      description: >-
        Use this operation to test a rules pattern that you plan to use to
        create an audience segment. For more information about segments, see
        CreateSegment.
      operationId: amazonWebServicesTestSegmentPattern
  /projects/{project}/data-delivery:
    PATCH:
      summary: Updateprojectdatadelivery
      description: >-
        Updates the data storage options for this project. If you store
        evaluation events, you an keep them and analyze them on your own. If you
        choose not to store evaluation events, Evidently deletes them after
        using them to produce metrics and other experiment results that you can
        view. You can't specify both cloudWatchLogs and s3Destination in the
        same operation.
      operationId: amazonWebServicesUpdateProjectDataDelivery
tags: []
