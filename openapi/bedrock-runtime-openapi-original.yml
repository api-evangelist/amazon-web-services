openapi: 3.1.0
info:
  title: bedrock-runtime
  description: >-
    <p>Describes the API operations for running inference using Bedrock
    models.</p>
paths:
  /model/{modelId}/invoke:
    POST:
      summary: Invokemodel
      description: >-
        Invokes the specified Bedrock model to run inference using the input
        provided in the request body. You use InvokeModel to run inference for
        text models, image models, and embedding models. For more information,
        see Run inference in the Bedrock User Guide. For example requests, see
        Examples (after the Errors section).
      operationId: amazonWebServicesInvokeModel
  /model/{modelId}/invoke-with-response-stream:
    POST:
      summary: Invokemodelwithresponsestream
      description: >-
        Invoke the specified Bedrock model to run inference using the input
        provided. Return the response in a stream. For more information, see Run
        inference in the Bedrock User Guide. For an example request and
        response, see Examples (after the Errors section).
      operationId: amazonWebServicesInvokeModelWithResponseStream
tags: []
